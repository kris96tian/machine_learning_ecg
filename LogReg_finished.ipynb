{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d077a4-b77e-4ddf-9800-7983d0d81540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pywt\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data modeling\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc0e702-dddd-44d9-818f-f3309dbe811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_samples = pd.read_csv(\"/home/ngsci/datasets/silent-cchs-ecg/csv/lead-samples-count.csv\")\n",
    "rwma_outcomes = pd.read_csv(\"/home/ngsci/datasets/silent-cchs-ecg/csv/rwma-outcomes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fca1e56-203e-45ed-a3a8-c8598ffb8b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df = pd.merge(lead_samples.drop(columns=['holdout']), rwma_outcomes, on='ecg_id')\n",
    "#merged_df\n",
    "#merged_dfs_arr = merged_df.values\n",
    "#print(merged_dfs_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a9bd51a-3946-4b50-932a-896bc224bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA loading\n",
    "npy_filepath = \"/home/ngsci/datasets/silent-cchs-ecg/npy\"\n",
    "dir_list = os.listdir(npy_filepath)\n",
    "npy_arrays = []\n",
    "for each in dir_list:\n",
    "    file = f\"{npy_filepath}/{each}\"\n",
    "    tempf = np.load(file)[:,:,0:5000]  \n",
    "    npy_arrays.append(tempf)\n",
    "    \n",
    "stacked = np.stack(npy_arrays, axis= 0)\n",
    "stacked = torch.from_numpy(stacked)\n",
    "stacked = stacked.permute(1,0,2,3)\n",
    "stacked = stacked.reshape(3750, 12*5000) # log Reg akz. 2D\n",
    "\n",
    "rwma = pd.read_csv(\"/home/ngsci/datasets/silent-cchs-ecg/csv/rwma-outcomes.csv\")\n",
    "rwma = rwma.astype(float)\n",
    "rwma = torch.tensor(rwma.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "369f4b81-5d3e-4b91-8277-7a5d50a07b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ekgData():\n",
    "    def __init__(self):\n",
    "        self.x = stacked\n",
    "        self.y = rwma\n",
    "        self.n_persons = len(self.y)\n",
    "\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.x, self.y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Further split the training set into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "        self.x_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.x_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.x_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def get_train_data(self): #get training data\n",
    "        # return as tuple\n",
    "        return self.x_train, self.y_train\n",
    "        \n",
    "    def get_val_data(self): #get validation data\n",
    "        # return as tuple\n",
    "        return self.x_val, self.y_val\n",
    "        \n",
    "    def get_test_data(self): #get testing data\n",
    "        # return as tuple\n",
    "        return self.x_test, self.y_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_persons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0db74ac1-bbe0-4bff-9855-850390e46013",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ekgData()\n",
    "x_train, y_train = data.get_train_data()\n",
    "x_val, y_val = data.get_val_data()\n",
    "x_test, y_test = data.get_test_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33e9b0e2-84ca-4090-b536-3a8f05a071f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confussion matrix\n",
      "[[356 318]\n",
      " [ 32  44]]\n",
      "\n",
      "\n",
      "Accuracy of Logistic Regression: 53.333333333333336 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.53      0.67       674\n",
      "         1.0       0.12      0.58      0.20        76\n",
      "\n",
      "    accuracy                           0.53       750\n",
      "   macro avg       0.52      0.55      0.44       750\n",
      "weighted avg       0.84      0.53      0.62       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "lr = LogisticRegression()\n",
    "model = lr.fit(x_train, y_train)\n",
    "lr_predict = lr.predict(x_test)\n",
    "lr_conf_matrix = confusion_matrix(y_test, lr_predict)\n",
    "lr_acc_score = accuracy_score(y_test, lr_predict)\n",
    "print(\"confussion matrix\")\n",
    "print(lr_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Logistic Regression:\",lr_acc_score*100,'\\n')\n",
    "print(classification_report(y_test,lr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f85d28-bb11-47b8-93df-9f966b76fc36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
